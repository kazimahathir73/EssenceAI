{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tasnu\\AppData\\Roaming\\Python\\Python312\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from transformers import T5Tokenizer, T5ForConditionalGeneration, AdamW\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>at least two people were killed in a suspected...</td>\n",
       "      <td>at least two dead in southern philippines blast\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>australian shares closed down #.# percent mond...</td>\n",
       "      <td>australian stocks close down #.# percent\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>south korea 's nuclear envoy kim sook urged no...</td>\n",
       "      <td>envoy urges north korea to restart nuclear dis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>south korea on monday announced sweeping tax r...</td>\n",
       "      <td>skorea announces tax cuts to stimulate economy\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taiwan share prices closed down #.## percent m...</td>\n",
       "      <td>taiwan shares close down #.## percent\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             article  \\\n",
       "0  at least two people were killed in a suspected...   \n",
       "1  australian shares closed down #.# percent mond...   \n",
       "2  south korea 's nuclear envoy kim sook urged no...   \n",
       "3  south korea on monday announced sweeping tax r...   \n",
       "4  taiwan share prices closed down #.## percent m...   \n",
       "\n",
       "                                             summary  \n",
       "0  at least two dead in southern philippines blast\\n  \n",
       "1         australian stocks close down #.# percent\\n  \n",
       "2  envoy urges north korea to restart nuclear dis...  \n",
       "3   skorea announces tax cuts to stimulate economy\\n  \n",
       "4            taiwan shares close down #.## percent\\n  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\tasnu\\\\OneDrive\\\\Documents\\\\EssenceAI\\\\summarizer_model\\\\gigadata_corpus.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['an experimental solar-powered aircraft cruising above switzerland in a historic bid to fly around the clock approached a turning point in its flight on wednesday as night-time loomed .\\n',\n",
       "       'knight ridder , the second-largest newspaper publisher in the country , reported higher earnings in the second quarter as executives saw continued signs of a turnaround in advertising .\\n',\n",
       "       'the body of ##-year-old alisa flatow arrived home wednesday morning , accompanied by her father , who donated her organs to help save israeli lives after she was killed in a suicide bombing in gaza .\\n',\n",
       "       'when good computers go bad , finding the cause can drive you bonkers .\\n',\n",
       "       \"the coroner examining the death of diana , princess of wales launched a scathing attack tuesday on her former butler , telling the jury at her inquest it was `` blindingly obvious '' he lied as a witness .\\n\",\n",
       "       'the construction of the beijing-kowloon railway has breathed new life into economic expansion along the entire line over the past two years .\\n',\n",
       "       'japanese share prices opened slightly higher tuesday , with the benchmark nikkei-### index rising ##.## points , or #.## percent , to #,###.## in the first minute of trading .\\n',\n",
       "       'voters in lesotho were casting their ballots saturday in their first local elections since the tiny southern african kingdom gained independence from britain in #### .\\n',\n",
       "       \"a nuclear reactor was restarted at ukraine 's rivne nuclear power plant following scheduled repairs , officials said sunday .\\n\",\n",
       "       'food and drinks giant nestle sa said monday it has completed its us$ #.# billion -lrb- euro# .# billion -rrb- takeover of novartis medical nutrition .\\n'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'].sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3803956 entries, 0 to 3803955\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Dtype \n",
      "---  ------   ----- \n",
      " 0   article  object\n",
      " 1   summary  object\n",
      "dtypes: object(2)\n",
      "memory usage: 58.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'#', '', text)\n",
    "    text = re.sub(r'\\n', '', text)\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
    "    return text\n",
    "\n",
    "df['article'] = df['article'].apply(clean_text)\n",
    "df['summary'] = df['summary'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the government of macao special administrative region lrb sar rrb will give full support to local cultural and creative industry by fostering more talents and establishing an industry cluster area  the sar s chief executive chui sai on said tuesday ',\n",
       "       'an exhibition of australian indigenous art  featuring  works by aborigines from unk hills  opened at the taipei fine arts museum lrb tfam rrb on friday ',\n",
       "       'health minister manto tshabalalamsimang boycotted south africa s national aids conference wednesday as she returned to work after a long absence following a liver transplant ',\n",
       "       'qiandao lake in chun  an county  zhejiang province  has become china s biggest wildlife zoo following  years of afforestation  and wild animal protection and breeding ',\n",
       "       'carl lewis was criticized by another former olympic sprint champion in new york on tuesday for skipping a reunion of meter olympic champions in unk of  olympic unk medalist jesse owens ',\n",
       "       'leaders of the  countries on the powerful un security council will meet during this month s un summit to put a spotlight on the need to stop inciting terrorism and to prevent conflicts  especially in africa ',\n",
       "       'for the second day in a row  mayor rudolph giuliani and police commissioner william bratton on friday assailed a federal judge for tossing out as evidence   million in drugs and a videotaped confession by a woman who admitted that she was transporting cocaine and heroin in her car ',\n",
       "       'intel corp and hewlettpackard co have reported manufacturing and design flaws that could affect some computers ',\n",
       "       'antigovernment protesters friday said they would renew their street demonstrations next week in a fresh bid to force thai prime minister thaksin shinawatra to leave office ',\n",
       "       'oil prices extended their decline in asian trading thursday after us government data showed a largerthanexpected increase in domestic inventories of gasoline and heating oil '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['article'].sample(10).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_t5(df, input_column, target_column):\n",
    "    inputs = \"summarize: \" + df[input_column]\n",
    "    targets = df[target_column]\n",
    "    return inputs.tolist(), targets.tolist()\n",
    "\n",
    "train_input, train_target = convert_to_t5(train_df, 'article', 'summary')\n",
    "test_input, test_target = convert_to_t5(test_df, 'article', 'summary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data and model load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Max length of train feature: {max(train_input)}')\n",
    "print(f'Max length of train Label: {max(train_target)}')\n",
    "print(f'Max length of test feature: {max(test_input)}')\n",
    "print(f'Max length of test target: {max(test_target)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained(\"t5-small\")\n",
    "model = T5ForConditionalGeneration.from_pretrained(\"t5-small\")\n",
    "\n",
    "def tokenize_data(inputs, targets, tokenizer, max_length=512):\n",
    "    input_encodings = tokenizer(inputs, max_length=max_length, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    target_encodings = tokenizer(targets, max_length=150, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    return input_encodings, target_encodings\n",
    "\n",
    "train_encodings, train_target_encodings = tokenize_data(train_input, train_target, tokenizer)\n",
    "test_encodings, test_target_encodings = tokenize_data(test_input, test_target, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextSummarizationDataset(Dataset):\n",
    "    def __init__(self, input_encodings, target_encodings):\n",
    "        self.input_encodings = input_encodings\n",
    "        self.target_encodings = target_encodings\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.input_encodings['input_ids'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input_ids = self.input_encodings['input_ids'][idx]\n",
    "        attention_mask = self.input_encodings['attention_mask'][idx]\n",
    "        labels = self.target_encodings['input_ids'][idx]\n",
    "\n",
    "        return {'input_ids': input_ids, 'attention_mask': attention_mask, 'labels': labels}\n",
    "\n",
    "train_dataset = TextSummarizationDataset(train_encodings, train_target_encodings)\n",
    "test_dataset = TextSummarizationDataset(test_encodings, test_target_encodings)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=10e-3)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "model.train()\n",
    "epoch_num = 5\n",
    "for epoch in range(epoch_num):\n",
    "    loop = tqdm(train_loader, leave=True)\n",
    "    for batch in loop:\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "        \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loop.set_description(f\"Epoch {epoch}\")\n",
    "        loop.set_postfix(loss=loss.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./t5_weights\")\n",
    "tokenizer.save_pretrained(\"./t5_tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "import torch\n",
    "\n",
    "# Load the saved model and tokenizer\n",
    "model_path = \"./t5_summarizer_model\"\n",
    "tokenizer_path = \"./t5_summarizer_tokenizer\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_path)\n",
    "tokenizer = T5Tokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "model.eval()  # Set the model to evaluation mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_paragraph(paragraph, max_length=150, min_length=30):\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(\"summarize: \" + paragraph, return_tensors=\"pt\", max_length=512, truncation=True).to(device)\n",
    "    \n",
    "    # Generate summary\n",
    "    summary_ids = model.generate(\n",
    "        inputs[\"input_ids\"], \n",
    "        max_length=max_length, \n",
    "        min_length=min_length, \n",
    "        length_penalty=2.0, \n",
    "        num_beams=4, \n",
    "        early_stopping=True\n",
    "    )\n",
    "    \n",
    "    # Decode the summary\n",
    "    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "    \n",
    "    return summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"The COVID-19 pandemic has caused a global economic slowdown. Governments around the world are taking measures to address the crisis. Health systems are under immense pressure, and countries are introducing emergency protocols to handle the situation.\"\"\"\n",
    "\n",
    "summary = summarize_paragraph(paragraph)\n",
    "print(\"Original Paragraph:\", paragraph)\n",
    "print(\"Summary:\", summary)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
